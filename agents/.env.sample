# Environment variables for MCP Agent
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b #You might also want to try something bigger like llama3.1:latest
TANKERKOENIG_API_KEY=your_api_key_here
ENABLE_STREAM=false #if set to true, streaming will be enabled for chat responses
ENABLE_THINKING=false #if set to true, ollama will set the thinking to be enabled
SHOW_THOUGHTS=true #if set to true, thoughts will be visible
MAX_TOOL_CALL_LOOPS_FOR_USERINPUT=4
OLLAMA_NUM_THREADS=8
OLLAMA_LOAD_TIMEOUT=15m

AGENT_ATHUR_PORT=10003

AGENT_WITH_TOOLS_SHOW_RESPONSES=true